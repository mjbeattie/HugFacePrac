***** Running Evaluation *****
  Num examples = 238
  Batch size = 8
Generate config GenerationConfig {
  "decoder_start_token_id": 0,
  "eos_token_id": 1,
  "pad_token_id": 0,
  "transformers_version": "4.26.1"
}

  0%|          | 0/30 [00:00<?, ?it/s]Generate config GenerationConfig {
  "decoder_start_token_id": 0,
  "eos_token_id": 1,
  "pad_token_id": 0,
  "transformers_version": "4.26.1"
}

  7%|▋         | 2/30 [00:00<00:03,  7.79it/s]Generate config GenerationConfig {
  "decoder_start_token_id": 0,
  "eos_token_id": 1,
  "pad_token_id": 0,
  "transformers_version": "4.26.1"
}

 10%|█         | 3/30 [00:00<00:05,  5.08it/s]Generate config GenerationConfig {
  "decoder_start_token_id": 0,
  "eos_token_id": 1,
  "pad_token_id": 0,
  "transformers_version": "4.26.1"
}

 13%|█▎        | 4/30 [00:00<00:05,  4.38it/s]Generate config GenerationConfig {
  "decoder_start_token_id": 0,
  "eos_token_id": 1,
  "pad_token_id": 0,
  "transformers_version": "4.26.1"
}

 17%|█▋        | 5/30 [00:01<00:06,  4.03it/s]Generate config GenerationConfig {
  "decoder_start_token_id": 0,
  "eos_token_id": 1,
  "pad_token_id": 0,
  "transformers_version": "4.26.1"
}

 20%|██        | 6/30 [00:01<00:06,  3.82it/s]Generate config GenerationConfig {
  "decoder_start_token_id": 0,
  "eos_token_id": 1,
  "pad_token_id": 0,
  "transformers_version": "4.26.1"
}

 23%|██▎       | 7/30 [00:01<00:05,  4.09it/s]Generate config GenerationConfig {
  "decoder_start_token_id": 0,
  "eos_token_id": 1,
  "pad_token_id": 0,
  "transformers_version": "4.26.1"
}

 27%|██▋       | 8/30 [00:01<00:05,  4.13it/s]Generate config GenerationConfig {
  "decoder_start_token_id": 0,
  "eos_token_id": 1,
  "pad_token_id": 0,
  "transformers_version": "4.26.1"
}

 30%|███       | 9/30 [00:02<00:05,  3.82it/s]Generate config GenerationConfig {
  "decoder_start_token_id": 0,
  "eos_token_id": 1,
  "pad_token_id": 0,
  "transformers_version": "4.26.1"
}

 33%|███▎      | 10/30 [00:02<00:05,  3.74it/s]Generate config GenerationConfig {
  "decoder_start_token_id": 0,
  "eos_token_id": 1,
  "pad_token_id": 0,
  "transformers_version": "4.26.1"
}

 37%|███▋      | 11/30 [00:02<00:05,  3.67it/s]Generate config GenerationConfig {
  "decoder_start_token_id": 0,
  "eos_token_id": 1,
  "pad_token_id": 0,
  "transformers_version": "4.26.1"
}

 40%|████      | 12/30 [00:02<00:04,  3.97it/s]Generate config GenerationConfig {
  "decoder_start_token_id": 0,
  "eos_token_id": 1,
  "pad_token_id": 0,
  "transformers_version": "4.26.1"
}

 43%|████▎     | 13/30 [00:03<00:04,  3.81it/s]Generate config GenerationConfig {
  "decoder_start_token_id": 0,
  "eos_token_id": 1,
  "pad_token_id": 0,
  "transformers_version": "4.26.1"
}

 47%|████▋     | 14/30 [00:03<00:04,  3.75it/s]Generate config GenerationConfig {
  "decoder_start_token_id": 0,
  "eos_token_id": 1,
  "pad_token_id": 0,
  "transformers_version": "4.26.1"
}

 50%|█████     | 15/30 [00:03<00:04,  3.72it/s]Generate config GenerationConfig {
  "decoder_start_token_id": 0,
  "eos_token_id": 1,
  "pad_token_id": 0,
  "transformers_version": "4.26.1"
}

 53%|█████▎    | 16/30 [00:03<00:03,  4.03it/s]Generate config GenerationConfig {
  "decoder_start_token_id": 0,
  "eos_token_id": 1,
  "pad_token_id": 0,
  "transformers_version": "4.26.1"
}

 57%|█████▋    | 17/30 [00:04<00:03,  4.12it/s]Generate config GenerationConfig {
  "decoder_start_token_id": 0,
  "eos_token_id": 1,
  "pad_token_id": 0,
  "transformers_version": "4.26.1"
}

 60%|██████    | 18/30 [00:04<00:03,  3.96it/s]Generate config GenerationConfig {
  "decoder_start_token_id": 0,
  "eos_token_id": 1,
  "pad_token_id": 0,
  "transformers_version": "4.26.1"
}

 63%|██████▎   | 19/30 [00:04<00:02,  3.82it/s]Generate config GenerationConfig {
  "decoder_start_token_id": 0,
  "eos_token_id": 1,
  "pad_token_id": 0,
  "transformers_version": "4.26.1"
}

 67%|██████▋   | 20/30 [00:05<00:02,  3.76it/s]Generate config GenerationConfig {
  "decoder_start_token_id": 0,
  "eos_token_id": 1,
  "pad_token_id": 0,
  "transformers_version": "4.26.1"
}

 70%|███████   | 21/30 [00:05<00:02,  3.67it/s]Generate config GenerationConfig {
  "decoder_start_token_id": 0,
  "eos_token_id": 1,
  "pad_token_id": 0,
  "transformers_version": "4.26.1"
}

 73%|███████▎  | 22/30 [00:05<00:02,  3.66it/s]Generate config GenerationConfig {
  "decoder_start_token_id": 0,
  "eos_token_id": 1,
  "pad_token_id": 0,
  "transformers_version": "4.26.1"
}

 77%|███████▋  | 23/30 [00:05<00:01,  3.76it/s]Generate config GenerationConfig {
  "decoder_start_token_id": 0,
  "eos_token_id": 1,
  "pad_token_id": 0,
  "transformers_version": "4.26.1"
}

 80%|████████  | 24/30 [00:06<00:01,  3.71it/s]Generate config GenerationConfig {
  "decoder_start_token_id": 0,
  "eos_token_id": 1,
  "pad_token_id": 0,
  "transformers_version": "4.26.1"
}

 83%|████████▎ | 25/30 [00:06<00:01,  3.68it/s]Generate config GenerationConfig {
  "decoder_start_token_id": 0,
  "eos_token_id": 1,
  "pad_token_id": 0,
  "transformers_version": "4.26.1"
}

 87%|████████▋ | 26/30 [00:06<00:01,  3.56it/s]Generate config GenerationConfig {
  "decoder_start_token_id": 0,
  "eos_token_id": 1,
  "pad_token_id": 0,
  "transformers_version": "4.26.1"
}

 90%|█████████ | 27/30 [00:06<00:00,  3.61it/s]Generate config GenerationConfig {
  "decoder_start_token_id": 0,
  "eos_token_id": 1,
  "pad_token_id": 0,
  "transformers_version": "4.26.1"
}

 93%|█████████▎| 28/30 [00:07<00:00,  3.53it/s]Generate config GenerationConfig {
  "decoder_start_token_id": 0,
  "eos_token_id": 1,
  "pad_token_id": 0,
  "transformers_version": "4.26.1"
}

 97%|█████████▋| 29/30 [00:07<00:00,  3.77it/s]Generate config GenerationConfig {
  "decoder_start_token_id": 0,
  "eos_token_id": 1,
  "pad_token_id": 0,
  "transformers_version": "4.26.1"
}

100%|██████████| 30/30 [00:08<00:00,  3.75it/s]
Saving model checkpoint to mt5-small-finetuned-amazon-en-es
Configuration saved in mt5-small-finetuned-amazon-en-es/config.json
Configuration saved in mt5-small-finetuned-amazon-en-es/generation_config.json
Model weights saved in mt5-small-finetuned-amazon-en-es/pytorch_model.bin
tokenizer config file saved in mt5-small-finetuned-amazon-en-es/tokenizer_config.json
Special tokens file saved in mt5-small-finetuned-amazon-en-es/special_tokens_map.json
Copy vocab file to mt5-small-finetuned-amazon-en-es/spiece.model
Upload file pytorch_model.bin: 100%|█████████▉| 1.11G/1.12G [03:04<00:00, 6.55MB/s]remote: Scanning LFS files of refs/heads/main for validity...        
remote: LFS file scan complete.        
To https://huggingface.co/mjbeattie/mt5-small-finetuned-amazon-en-es
   0d5a7fb..6684cac  main -> main

WARNING:huggingface_hub.repository:remote: Scanning LFS files of refs/heads/main for validity...        
remote: LFS file scan complete.        
To https://huggingface.co/mjbeattie/mt5-small-finetuned-amazon-en-es
   0d5a7fb..6684cac  main -> main

Upload file pytorch_model.bin: 100%|██████████| 1.12G/1.12G [03:06<00:00, 6.44MB/s]
Dropping the following result as it does not have all the necessary fields:
{'task': {'name': 'Sequence-to-sequence Language Modeling', 'type': 'text2text-generation'}, 'metrics': [{'name': 'Rouge1', 'type': 'rouge', 'value': 17.0969}]}
To https://huggingface.co/mjbeattie/mt5-small-finetuned-amazon-en-es
   6684cac..5f542bf  main -> main

WARNING:huggingface_hub.repository:To https://huggingface.co/mjbeattie/mt5-small-finetuned-amazon-en-es
   6684cac..5f542bf  main -> main

